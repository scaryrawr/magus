import { describe, expect, it } from "bun:test";
import { OllamaShowSchema, OllamaTagsSchema } from "./ollama";

describe("parsing ollama tags", () => {
  const apiResponse = {
    models: [
      {
        name: "gpt-oss:latest",
        model: "gpt-oss:latest",
        modified_at: "2025-08-14T08:57:17.395622594-04:00",
        size: 13_780_173_724,
        digest: "aa4295ac10c3afb60e6d711289fc6896f5aef82258997b9efdaed6d0cc4cd8b8",
        details: {
          parent_model: "",
          format: "gguf",
          family: "gptoss",
          families: ["gptoss"],
          parameter_size: "20.9B",
          quantization_level: "MXFP4",
        },
      },
      {
        name: "qwen3:14b",
        model: "qwen3:14b",
        modified_at: "2025-08-13T22:19:35.441046942-04:00",
        size: 9_276_198_565,
        digest: "bdbd181c33f2ed1b31c972991882db3cf4d192569092138a7d29e973cd9debe8",
        details: {
          parent_model: "",
          format: "gguf",
          family: "qwen3",
          families: ["qwen3"],
          parameter_size: "14.8B",
          quantization_level: "Q4_K_M",
        },
      },
    ],
  };

  it("should parse the tags", () => {
    const result = OllamaTagsSchema.parse(apiResponse);
    expect(result.models.length).toBeGreaterThan(0);
  });
});

describe("parsing ollama show api", () => {
  const apiResponse = {
    license: "Apache License",
    modelfile: "# Modelfile generated by ...",
    parameters: "repeat_penalty ...",
    template: "template file...",
    details: {
      parent_model: "",
      format: "gguf",
      family: "qwen3",
      families: ["qwen3"],
      parameter_size: "32.8B",
      quantization_level: "Q4_K_M",
    },
    model_info: {
      "general.architecture": "qwen3",
      "general.basename": "Qwen3",
      "general.file_type": 15,
      "general.parameter_count": 32_762_123_264,
      "general.quantization_version": 2,
      "general.size_label": "32B",
      "general.type": "model",
      "qwen3.attention.head_count": 64,
      "qwen3.attention.head_count_kv": 8,
      "qwen3.attention.key_length": 128,
      "qwen3.attention.layer_norm_rms_epsilon": 0.000_001,
      "qwen3.attention.value_length": 128,
      "qwen3.block_count": 64,
      "qwen3.context_length": 40_960,
      "qwen3.embedding_length": 5120,
      "qwen3.feed_forward_length": 25_600,
      "qwen3.rope.freq_base": 1_000_000,
      "tokenizer.ggml.add_bos_token": false,
      "tokenizer.ggml.bos_token_id": 151_643,
      "tokenizer.ggml.eos_token_id": 151_645,
      "tokenizer.ggml.merges": undefined,
      "tokenizer.ggml.model": "gpt2",
      "tokenizer.ggml.padding_token_id": 151_643,
      "tokenizer.ggml.pre": "qwen2",
      "tokenizer.ggml.token_type": undefined,
      "tokenizer.ggml.tokens": undefined,
    },
    tensors: [
      {
        name: "output.weight",
        type: "Q6_K",
        shape: [5120, 151_936],
      },
      {
        name: "output_norm.weight",
        type: "F32",
        shape: [5120],
      },
      {
        name: "token_embd.weight",
        type: "Q4_K",
        shape: [5120, 151_936],
      },
    ],
    capabilities: ["completion", "tools", "thinking"],
    modified_at: "2025-08-14T09:09:29.342056559-04:00",
  };

  it("show parses successfully", () => {
    const result = OllamaShowSchema.parse(apiResponse);
    const arch = result.model_info["general.architecture"];
    const contextLength = result.model_info[`${arch}.context_length`];
    expect(contextLength).toBeDefined();
    expect(contextLength).toEqual(40_960);
  });
});
